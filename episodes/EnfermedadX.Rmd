---
title: "Estimaci贸n de las distribuciones de rezagos epidemiol贸gicos: Enfermedad X (Grupo 1)"
author: "Kelly Charniga, PhD MPH & Zulma Cuucnub谩 MD, PhD"
date: "2023-11-23"
output: html_document
teaching: 90
exercises: 8
---

```{r include=FALSE}

## calculates the DIC likelihood by integration
diclik <- function(par1, par2, EL, ER, SL, SR, dist){
	
	## if symptom window is bigger than exposure window
	if(SR-SL>ER-EL){
		dic1 <- integrate(fw1, lower=SL-ER, upper=SL-EL,
						  subdivisions=10,
						  par1=par1, par2=par2,
						  EL=EL, ER=ER, SL=SL, SR=SR,
						  dist=dist)$value
		if (dist == "W"){
			dic2 <- (ER-EL)*
				(pweibull(SR-ER, shape=par1, scale=par2) - pweibull(SL-EL, shape=par1, scale=par2))
		} else if (dist == "off1W"){
			dic2 <- (ER-EL)*
				(pweibullOff1(SR-ER, shape=par1, scale=par2) - pweibullOff1(SL-EL, shape=par1, scale=par2))
		} else if (dist == "G"){
			dic2 <- (ER-EL)*
				(pgamma(SR-ER, shape=par1, scale=par2) - pgamma(SL-EL, shape=par1, scale=par2))
		} else if (dist == "off1G"){
			dic2 <- (ER-EL)*
				(pgammaOff1(SR-ER, shape=par1, scale=par2) - pgammaOff1(SL-EL, shape=par1, scale=par2))
		} else if (dist == "L") {
			dic2 <- (ER-EL)*
				(plnorm(SR-ER, par1, par2) - plnorm(SL-EL, par1, par2))
		} else if (dist == "off1L") {
			dic2 <- (ER-EL)*
				(plnormOff1(SR-ER, par1, par2) - plnormOff1(SL-EL, par1, par2))
		} else {
			stop("distribution not supported")
		}
		dic3 <- integrate(fw3, lower=SR-ER, upper=SR-EL,
						  subdivisions=10,
						  par1=par1, par2=par2,
						  EL=EL, ER=ER, SL=SL, SR=SR,
						  dist=dist)$value
		return(dic1 + dic2 + dic3)
	}
	
	## if exposure window is bigger than symptom window
	else{
		dic1 <- integrate(fw1, lower=SL-ER, upper=SR-ER, subdivisions=10,
						  par1=par1, par2=par2,
						  EL=EL, ER=ER, SL=SL, SR=SR,
						  dist=dist)$value
		if (dist == "W"){
			dic2 <- (SR-SL)*
				(pweibull(SL-EL, shape=par1, scale=par2) - pweibull(SR-ER, shape=par1, scale=par2))
		} else if (dist == "off1W"){
			dic2 <- (SR-SL)*
				(pweibullOff1(SL-EL, shape=par1, scale=par2) - pweibullOff1(SR-ER, shape=par1, scale=par2))
		} else if (dist == "G"){
			dic2 <- (SR-SL)*
				(pgamma(SL-EL, shape=par1, scale=par2) - pgamma(SR-ER, shape=par1, scale=par2))
		} else if (dist == "off1G"){
			dic2 <- (SR-SL)*
				(pgammaOff1(SL-EL, shape=par1, scale=par2) - pgammaOff1(SR-ER, shape=par1, scale=par2))
		} else if (dist == "L"){
			dic2 <- (SR-SL)*
				(plnorm(SL-EL, par1, par2) - plnorm(SR-ER, par1, par2))
		} else if (dist == "off1L"){
			dic2 <- (SR-SL)*
				(plnormOff1(SL-EL, par1, par2) - plnormOff1(SR-ER, par1, par2))
		} else {
			stop("distribution not supported")
		}
		dic3 <- integrate(fw3, lower=SL-EL, upper=SR-EL,
						  subdivisions=10,
						  par1=par1, par2=par2,
						  EL=EL, ER=ER, SL=SL, SR=SR,
						  dist=dist)$value
		return(dic1 + dic2 + dic3)
	}
}

## this dic likelihood is designed for data that has overlapping intervals
diclik2 <- function(par1, par2, EL, ER, SL, SR, dist){
	if(SL>ER) {
		
		return(diclik(par1, par2, EL, ER, SL, SR, dist))
	} else {
		
		lik1 <- integrate(diclik2.helper1, lower=EL, upper=SL,
						  SL=SL, SR=SR, par1=par1, par2=par2, dist=dist)$value
		lik2 <- integrate(diclik2.helper2, lower=SL, upper=ER,
						  SR=SR, par1=par1, par2=par2, dist=dist)$value
		return(lik1+lik2)
	}
}

## likelihood functions for diclik2
diclik2.helper1 <- function(x, SL, SR, par1, par2, dist){
	if (dist =="W"){
		pweibull(SR-x, shape=par1, scale=par2) - pweibull(SL-x, shape=par1, scale=par2)
	} else if (dist =="off1W") {
		pweibullOff1(SR-x, shape=par1, scale=par2) - pweibullOff1(SL-x, shape=par1, scale=par2)
	} else if (dist =="G") {
		pgamma(SR-x, shape=par1, scale=par2) - pgamma(SL-x, shape=par1, scale=par2)
	} else if (dist=="off1G"){
		pgammaOff1(SR-x, shape=par1, scale=par2) - pgammaOff1(SL-x, shape=par1, scale=par2)
	} else if (dist == "L"){
		plnorm(SR-x, par1, par2) - plnorm(SL-x, par1, par2)
	} else if (dist == "off1L"){
		plnormOff1(SR-x, par1, par2) - plnormOff1(SL-x, par1, par2)
	} else {
		stop("distribution not supported")     
	}
}

diclik2.helper2 <- function(x, SR, par1, par2, dist){
	if (dist =="W"){
		pweibull(SR-x, shape=par1, scale=par2)
	} else if (dist =="off1W") {
		pweibullOff1(SR-x, shape=par1, scale=par2)
	} else if (dist =="G") {
		pgamma(SR-x, shape=par1, scale=par2)
	} else if (dist =="off1G") {
		pgammaOff1(SR-x, shape=par1, scale=par2)
	} else if (dist=="L"){
		plnorm(SR-x, par1, par2)
	} else if (dist=="off1L"){
		plnormOff1(SR-x, par1, par2)
	} else {
		stop("distribution not supported")     
	}
}

## functions that manipulate/calculate the likelihood for the censored data
## the functions coded here are taken directly from the
## doubly interval censored likelihood notes.
fw1 <- function(t, EL, ER, SL, SR, par1, par2, dist){
	## function that calculates the first function for the DIC integral
	if (dist=="W"){
		(ER-SL+t) * dweibull(x=t,shape=par1,scale=par2)
	} else if (dist=="off1W") {
		(ER-SL+t) * dweibullOff1(x=t,shape=par1,scale=par2)
	} else if (dist=="G") {
		(ER-SL+t) * dgamma(x=t, shape=par1, scale=par2)
	} else if (dist=="off1G") {
		(ER-SL+t) * dgammaOff1(x=t, shape=par1, scale=par2)
	} else if (dist =="L"){
		(ER-SL+t) * dlnorm(x=t, meanlog=par1, sdlog=par2)
	} else if (dist =="off1L"){
		(ER-SL+t) * dlnormOff1(x=t, meanlog=par1, sdlog=par2)
	} else {
		stop("distribution not supported")
	}
}

fw3 <- function(t, EL, ER, SL, SR, par1, par2, dist){
	## function that calculates the third function for the DIC integral
	if (dist == "W"){
		(SR-EL-t) * dweibull(x=t, shape=par1, scale=par2)
	} else if (dist == "off1W"){
		(SR-EL-t) * dweibullOff1(x=t, shape=par1, scale=par2)
	}  else if (dist == "G"){
		(SR-EL-t) * dgamma(x=t, shape=par1, scale=par2)
	}  else if (dist == "off1G"){
		(SR-EL-t) * dgammaOff1(x=t, shape=par1, scale=par2)
	} else if (dist == "L") {
		(SR-EL-t) * dlnorm(x=t, meanlog=par1, sdlog=par2)
	} else if (dist == "off1L"){
		(SR-EL-t) * dlnormOff1(x=t, meanlog=par1, sdlog=par2)
	} else {
		stop("distribution not supported")
	}
}

calc_looic_waic <- function(symp, symp_si, dist){
  # Prepare data and parameters for loo package
  # Need: an S by N matrix, where S is the size of the posterior sample (with all chains
  # merged) and N is the number of data points
  
  mat <- matrix(NA, nrow = length(symp_si@samples$var1), ncol = nrow(si_data)) 
  
for (i in 1:nrow(symp)) {
  for (j in 1:length(symp_si@samples$var1)){
    L <- diclik2(par1 = symp_si@samples$var1[j],
                 par2 = symp_si@samples$var2[j], 
                 EL = symp$EL[i], ER = symp$ER[i], SL = symp$SL[i], SR = symp$SR[i], 
                 dist = dist)
    mat[j,i] <- L
  }
}
  return(list(waic = waic(log(mat)),
              looic = loo(log(mat)))) # now we have to take the log to get log likelihood

}
```

:::::::::::::::::::::::::::::::::::::: questions 
 
- 驴C贸mo responder ante un brote de una enfermedad desconocida?

::::::::::::::::::::::::::::::::::::::::::::::::

::::::::::::::::::::::::::::::::::::: objectives

Al final de este taller usted podr谩: 
 
- Comprender los conceptos clave de las distribuciones de rezagos epidemiol贸gicos para la Enfermedad X. 
 
- Comprender las estructuras de datos y las herramientas para el an谩lisis de datos de rastreo de contactos. 
 
- Aprender a ajustar las estimaciones del intervalo serial y el per铆odo de incubaci贸n de la Enfermedad X teniendo en cuenta la censura por intervalo utilizando un marco de trabajo Bayesiano.
 
- Aprender a utilizar estos par谩metros para informar estrategias de control en un brote de un pat贸geno desconocido. 
::::::::::::::::::::::::::::::::::::::::::::::::

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### 1. Introducci贸n

La Enfermedad X representa un hipot茅tico, pero plausible, brote de una enfermedad infecciosa en el futuro. Este t茅rmino fue acu帽ado por la Organizaci贸n Mundial de la Salud (OMS) y sirve como un t茅rmino general para un pat贸geno desconocido que podr铆a causar una epidemia grave a nivel internacional. Este concepto representa la naturaleza impredecible de la aparici贸n de enfermedades infecciosas y resalta la necesidad de una preparaci贸n global y mecanismos de respuesta r谩pida. La Enfermedad X simboliza el potencial de una enfermedad inesperada y de r谩pida propagaci贸n, y resalta la necesidad de sistemas de salud flexibles y adaptables, as铆 como capacidades de investigaci贸n para identificar, comprender y combatir pat贸genos desconocidos.

En esta pr谩ctica, va a aprender a estimar los rezagos epidemiol贸gicos, el tiempo entre dos eventos epidemiol贸gicos, utilizando un conjunto de datos simulado de la Enfermedad X.

La Enfermedad X es causada por un pat贸geno desconocido y se transmite directamente de persona a persona. Espec铆ficamente, la practica se centrar谩 en estimar el per铆odo de incubaci贸n y el intervalo serial.




### 2. Agenda

Parte 1. Individual o en grupo.

Parte 2. En 5 grupos de 8 personas. Construir estrategia de rastreo de contactos  y aislamiento y preparar presentaci贸n de m谩ximo 10 mins.



### 3. Key Concepts

#### **3.1. Epidemiological delays: incubation period and serial interval**

In epidemiology, delay distributions refer to the *time lags* between two key events during an outbreak. For example: the time between the symptoms onset and diagnosis, the time between symptom onset and death, among many others.

Today we will be focusing on two key delays known as the incubation period and serial interval. Both are crucial for informing public health response.

The [**incubation period**]{.underline} is the time between infection and symptom onset.

The [**serial interval**]{.underline} is the time between symptom onset in a primary and secondary case pair.

The relationship between these quantities have an impact on whether the disease transmits before [(**pre-symptomatic transmission)**]{.underline} or after symptoms [**(symptomatic transmission)**]{.underline} have developed in the primary case (Figure 1).

![](practicalfig.jpg)

Figure 1. Relationship between the incubation period and serial interval on the timing of transmission (*Adapted from Nishiura et al. 2020)*

#### 3.2. Common delay distributions and potential biases

##### **3.2.1 Potential biases**

When estimating epidemiological delays, it is important to consider potential biases:

[**Censoring**]{.underline} means that we know an event happened, but we do not know exactly when it happened. Most epidemiological data are "doubly censored" because there is uncertainty surrounding both primary and secondary event times. Not accounting for censoring can lead to biased estimates of the delay's standard deviation (Park et al. in progress).

[**Right truncation**]{.underline} is a type of sampling bias related to the data collection process. It arises because only cases that have been reported can be observed. Not accounting for right truncation during the growth phase of an epidemic can lead to underestimation of the mean delay (Park et al. in progress).

[**Dynamical (or epidemic phase)**]{.underline} **bias** is another type of sampling bias. It affects backward-looking data and is related to the phase of the epidemic: during the exponential growth phase, cases that developed symptoms recently are over-represented in the observed data, while during the declining phase, these cases are underrepresented, leading to the estimation of shorter and longer delay intervals, respectively (Park et al. in progress).

##### **3.2.2 Delay distributions**

Three common probability distributions used to characterize delays in infectious disease epidemiology include the following (Table 1):

+----------------+-----------------------------------------+
| Distribution   | Parameters                              |
+================+:=======================================:+
| **Weibull**    | `shape` and `scale`                     |
+----------------+-----------------------------------------+
| **gamma**      | `shape` and `scale`                     |
+----------------+-----------------------------------------+
| **log normal** | `log mean` and `log standard deviation` |
+----------------+-----------------------------------------+

: Table 1. Three of the most common probability distributions for epidemiological delays.

### 4. *R* packages for the practical

We will use the following `R` packages in this practical:

-   `dplyr` for data handling

-   `epicontacts` to visualize contact tracing data

-   `ggplot2` and `patchwork` for plotting

-   `incidence` to visualize epidemic curves

-   `rstan` to estimate the incubation period

-   `coarseDataTools` via `EpiEstim` to estimate the serial interval

Installation instructions for packages:

```{r install_packages, echo=FALSE}
## Packages on CRAN
#install.packages("dplyr")
#install.packages("incidence")
#install.packages("coarseDataTools")
#install.packages("EpiEstim")
#install.packages("ggplot2)
#install.packages("loo")
#install.packages("patchwork")
#install.packages("rstan")
#install.packages("parallel")
#
## Packages on GitHub
#remotes::install_github("reconhub/epicontacts")
```

To load the packages, type:

```{r load_packages, warning=FALSE, message=FALSE}
library(dplyr)
library(epicontacts)
library(incidence)
library(coarseDataTools)
library(EpiEstim)
library(ggplot2)
library(loo)
library(patchwork)
library(rstan)
```

## 5. Data

We are going to split into two groups for this practical to tackle two unknown diseases with different modes of transmission.

Let's load the simulated data, which is saved as a `.RDS` file.

There are two items of interest:

-   `linelist`, a file that contains one case of Disease X per row.

-   `contacts`, a file with contact tracing data which contains information about primary and secondary case pairs.

```{r load dat, echo=FALSE}
# Group 1
dat <- readRDS("Data/practical_data_group1.RDS")
linelist <- dat$linelist
contacts <- dat$contacts

# Group 2
#dat <- readRDS("Data/practical_data_group2.RDS")
#linelist <- dat$linelist
#contacts <- dat$contacts

```

## 6. Data exploration

#### **6.1. Exploring `linelist` data**

Let's start with the `linelist`. These data were collected as part of routine epidemiological surveillance. Each row represents one case of Disease X, and there are 7 variables:

-   `id`: unique case id number

-   `date_onset`: the patient's symptom onset date

-   `sex`: M = male; F = female

-   `age`: the patient's age in years

-   `exposure`: information about how the patient might have been exposed

-   `exposure_start`: earliest date that the patient was exposed

-   `exposure_end`: latest date that the patient was exposed

::: {.alert .alert-secondary}
+-----------------------------------------------------------------+
| ::: {.alert .alert-secondary}                                   |
| * **Questions (1)***                                          |
|                                                                 |
| -   *How many cases are in the `linelist` dataset?*             |
|                                                                 |
| -   *What proportion of the cases are female?*                  |
|                                                                 |
| -   *What is the age distribution of cases?*                    |
|                                                                 |
| -   *What type of exposure information is available?*           |
| :::                                                             |
+-----------------------------------------------------------------+
:::

```{r data exploration}
# Inspect data
head(linelist)
# Q1
nrow(linelist)
# Q2
table(linelist$sex)[2]/nrow(linelist)
#Q3
summary(linelist$age)
#Q4
table(linelist$exposure, exclude = F)[1]/nrow(linelist)

```

::: {.alert .alert-secondary}
+--------------------------------------------------------------------------------------------------------+
| ::: {.alert .alert-secondary}                                                                          |
| * **Discuss***                                                                                       |
|                                                                                                        |
| Why do you think the exposure information is missing for some cases?                                   |
|                                                                                                        |
| Now let's plot the epidemic curve. Where in the outbreak do you think we are (beginning, middle, end)? |
| :::                                                                                                    |
+--------------------------------------------------------------------------------------------------------+
:::

```{r epi curve, warning = FALSE, message = FALSE}
i <- incidence(linelist$date_onset)
plot(i) + 
  theme_classic() + 
  scale_fill_manual(values = "purple") +
  theme(legend.position = "none")
```

It looks like the epidemic might still be growing.

#### **6.2. Exploring `contact tracing` data**

Now let's look at the contact tracing data, which were obtained through patient interviews. Patients were asked about recent activities and interactions to identify possible sources of infection. Primary and secondary case pairs were matched if the secondary case named the primary case as a contact. We only have information on a subset of the cases because not all patients could be contacted for an interview.

Note that for this exercise, we will assume that the secondary cases only had one possible infector. In reality, the potential for a case to have multiple possible infectors needs to be assessed.

The contact tracing data has 4 variables:

-   `primary_case_id`: unique id number for the primary case (infector)

-   `secondary_case_id`: unique id number for the secondary case (infectee)

-   `primary_onset_date`: symptom onset date of the primary case

-   `secondary_onset_date`: symptom onset date of the secondary case

```{r contacts}
x <- make_epicontacts(linelist = linelist,
                       contacts = contacts,
                       from = "primary_case_id",
                       to = "secondary_case_id",
                       directed = TRUE) # This indicates that contacts are directed (i.e., this draws arrows from primary to secondary cases)

plot(x)

```

::: {.alert .alert-secondary}
+----------------------------------------------------------------------------------------------------------------+
| ::: {.alert .alert-secondary}                                                                                  |
| * **Questions (2)***                                                                                         |
|                                                                                                                |
| -   Describe the clusters.                                                                                     |
|                                                                                                                |
| -   Do you see any potential superspreading events (where one cases spreads the pathogen to many other cases)? |
| :::                                                                                                            |
+----------------------------------------------------------------------------------------------------------------+
:::

# *`_______Wrap-up 1 _________`*

------------------------------------------------------------------------

## 7. Estimating the incubation period

Now let's focus on the incubation period. We will use the `linelist` for this part. We need both time of symptom onset and time of possible exposure. Notice that there are two dates for exposure, a start and end, in the data. Sometimes the exact date of exposure is unknown and exposure window is provided during case interviews instead.

::: {.alert .alert-secondary}
* **Questions (3)***

-   For how many cases do we have data on both dates of symptom onset and exposure?

-   Calculate the exposure windows. How many cases have a single date of exposure?
:::

```{r estimate ip, warning = FALSE}
ip <- filter(linelist, !is.na(exposure_start) &
               !is.na(exposure_end))
nrow(ip)

ip$exposure_window <- as.numeric(ip$exposure_end - ip$exposure_start)

table(ip$exposure_window)

```

### 7.1. Naive estimate of the incubation period

Let's start by calculating a naive estimate of the incubation period.

```{r naive}
# Max incubation period 
ip$max_ip <- ip$date_onset - ip$exposure_start
summary(as.numeric(ip$max_ip))

# Minimum incubation period
ip$min_ip <- ip$date_onset - ip$exposure_end
summary(as.numeric(ip$min_ip))

```

### 7.2. Censoring adjusted estimate of the incubation period

Now let's fit three probability distributions to the incubation period data accounting for double censoring. We will adapt some `stan` code that was published by Miura et al. during the 2022 global mpox outbreak. This method does not account for right truncation or dynamical bias.

Remember we are mainly interested in considering three probability distributions: *Weibull*, *gamma*, and *log normal* (See Table 1).

`Stan` is a software program that implements the Hamiltonian Monte Carlo (HMC) algorithm. HMC is a Markov chain Monte Carlo (MCMC) method for fitting complex models to data using Bayesian statistics.

#### **7.1.1. Running the model in Stan**

We will fit all three distributions in this code chunk.

```{r correct ip}
# Prepare data
earliest_exposure <- as.Date(min(ip$exposure_start))

ip <- ip |>
  mutate(date_onset = as.numeric(date_onset - earliest_exposure),
         exposure_start = as.numeric(exposure_start - earliest_exposure),
         exposure_end = as.numeric(exposure_end - earliest_exposure)) |>
  select(id, date_onset, exposure_start, exposure_end)

# Setting some options to run the MCMC chains in parallel
# Running the MCMC chains in parallel means that we will run multiple MCMC chains at the same time by using multiple cores on your computer
options(mc.cores=parallel::detectCores())

input_data <- list(N = length(ip$exposure_start), # Number of observations
              tStartExposure = ip$exposure_start,
              tEndExposure = ip$exposure_end,
              tSymptomOnset = ip$date_onset)

# We are going to fit three probability distributions
distributions <- c("weibull", "gamma", "lognormal") 

# Stan code
code <- sprintf("
  data{
    int<lower=1> N;
    vector[N] tStartExposure;
    vector[N] tEndExposure;
    vector[N] tSymptomOnset;
  }
  parameters{
    real<lower=0> par[2];
    vector<lower=0, upper=1>[N] uE;	// Uniform value for sampling between start and end exposure
  }
  transformed parameters{
    vector[N] tE; 	// infection moment
    tE = tStartExposure + uE .* (tEndExposure - tStartExposure);
  }
model{
    // Contribution to likelihood of incubation period
    target += %s_lpdf(tSymptomOnset -  tE  | par[1], par[2]);
  }
  generated quantities {
    // likelihood for calculation of looIC
    vector[N] log_lik;
    for (i in 1:N) {
      log_lik[i] = %s_lpdf(tSymptomOnset[i] -  tE[i]  | par[1], par[2]);
    }
  }
", distributions, distributions)
names(code) <- distributions

# Next line takes ~1.5 min
models <- mapply(stan_model, model_code = code)

# Takes ~40 sec.
fit <- mapply(sampling, models, list(input_data), 
              iter=3000, # Number of iterations (length of MCMC chains)
              warmup=1000, # Number of samples to discard at the beginning of MCMC
              chain=4) # Number of chains to run MCMC

pos <- mapply(function(z) rstan::extract(z)$par, fit, SIMPLIFY=FALSE) # Posterior samples

```

#### **7.1.2. Checking for convergence**

Now we will check for model convergence. We will look at r-hat values, effective sample sizes, and the MCMC traces. R-hat compares the between- and within-chain estimates for model parameters; values near 1 tell us that chains have mixed well (Vehtari et al. 2021). The effective sample size estimates the number of independent samples after accounting for dependence in the MCMC chains (Lambert 2018). For a model with 4 MCMC chains, a total effective sample size of at least 400 is recommended (Vehtari et al. 2021).

For each model of different fitted distributions:

::: {.alert .alert-secondary}
* **Questions (4)***

-   Are the r-hat values close to 1?

-   Do the 4 MCMC chains generally lay on top of each other and stay around the same values (look like fuzzy caterpillars)?
:::

#### **7.1.2.1. Convergence for Gamma**

```{r convergence gamma}
print(fit$gamma, digits = 3, pars = c("par[1]","par[2]")) 
rstan::traceplot(fit$gamma, pars = c("par[1]","par[2]"))
```

#### **7.1.2.2. Convergence for log normal**

```{r convergence lognormal}
print(fit$lognormal, digits = 3, pars = c("par[1]","par[2]")) 
rstan::traceplot(fit$lognormal, pars = c("par[1]","par[2]")) 
```

#### **7.1.2.3. Convergence for Weibull**

```{r convergence weibull}
print(fit$weibull, digits = 3, pars = c("par[1]","par[2]")) 
rstan::traceplot(fit$weibull, pars = c("par[1]","par[2]")) 
```

#### **7.1.3. Compute model comparison criteria**

Let's compute the widely applicable information criterion (WAIC) and leave-one-out-information criterion (LOOIC) to compare model fits. The best fitting model is the model with the lowest WAIC or LOOIC. We will also summarize the distributions and make some plots.

::: {.alert .alert-secondary}
* **Questions (5)***

-   Which model has the best fit?
:::

#### 

```{r looic and waic ip, warning=FALSE, message=FALSE}
# Compute WAIC for all three models
waic <- mapply(function(z) waic(extract_log_lik(z))$estimates[3,], fit)
waic

# For looic, we need to provide the relative effective sample sizes
# when calling loo. This step leads to better estimates of the PSIS effective
# sample sizes and Monte Carlo error

# Extract pointwise log-likelihood for the Weibull distribution
loglik <- extract_log_lik(fit$weibull, merge_chains = FALSE)
# Get the relative effective sample sizes
r_eff <- relative_eff(exp(loglik), cores = 2)
# Compute LOOIC
loo_w <- loo(loglik, r_eff = r_eff, cores = 2)$estimates[3,]
# Print the results
loo_w[1]

# Extract pointwise log-likelihood for the gamma distribution
loglik <- extract_log_lik(fit$gamma, merge_chains = FALSE)
r_eff <- relative_eff(exp(loglik), cores = 2)
loo_g <- loo(loglik, r_eff = r_eff, cores = 2)$estimates[3,]
loo_g[1]

# Extract pointwise log-likelihood for the log normal distribution
loglik <- extract_log_lik(fit$lognormal, merge_chains = FALSE)
r_eff <- relative_eff(exp(loglik), cores = 2)
loo_l <- loo(loglik, r_eff = r_eff, cores = 2)$estimates[3,]
loo_l[1]

```

#### **7.1.4. Report the results**

The right tail of the incubation period distribution is important for designing control strategies (e.g. quarantine), the 25th-75th percentiles tells us about the most likely time symptom onset could occur, and the full distribution can be used as an input in mathematical or statistical models, like for forecasting (Lessler et al. 2009).

Let's get the summary statistics.

```{r reporting res}
# We need to convert the parameters of the distributions to the mean and standard deviation delay

# In Stan, the parameters of the distributions are:
# Weibull: shape and scale
# Gamma: shape and inverse scale (aka rate)
# Log normal: mu and sigma
# Reference: https://mc-stan.org/docs/2_21/functions-reference/positive-continuous-distributions.html
means <- cbind(pos$weibull[,2]*gamma(1+1/pos$weibull[,1]), # mean of Weibull
               pos$gamma[,1] / pos$gamma[,2], # mean of gamma
               exp(pos$lognormal[,1]+pos$lognormal[,2]^2/2)) # mean of log normal

standard_deviations <- cbind(sqrt(pos$weibull[,2]^2*(gamma(1+2/pos$weibull[,1])-(gamma(1+1/pos$weibull[,1]))^2)),
                             sqrt(pos$gamma[,1]/(pos$gamma[,2]^2)),
                             sqrt((exp(pos$lognormal[,2]^2)-1) * (exp(2*pos$lognormal[,1] + pos$lognormal[,2]^2))))

# Print the mean delays and 95% credible intervals
probs <- c(0.025, 0.5, 0.975)

res_means <- apply(means, 2, quantile, probs)
colnames(res_means) <- colnames(waic)
res_means

res_sds <- apply(standard_deviations, 2, quantile, probs)
colnames(res_sds) <- colnames(waic)
res_sds

# Report the median and 95% credible intervals for the quantiles of each distribution
quantiles_to_report <- c(0.025, 0.05, 0.5, 0.95, 0.975, 0.99)

# Weibull
cens_w_percentiles <- sapply(quantiles_to_report, function(p) quantile(qweibull(p = p, shape = pos$weibull[,1], scale = pos$weibull[,2]), probs = probs))
colnames(cens_w_percentiles) <- quantiles_to_report
print(cens_w_percentiles)

# Gamma
cens_g_percentiles <- sapply(quantiles_to_report, function(p) quantile(qgamma(p = p, shape = pos$gamma[,1], rate = pos$gamma[,2]), probs = probs))
colnames(cens_g_percentiles) <- quantiles_to_report
print(cens_g_percentiles)

# Log normal
cens_ln_percentiles <- sapply(quantiles_to_report, function(p) quantile(qlnorm(p = p, meanlog = pos$lognormal[,1], sdlog= pos$lognormal[,2]), probs = probs))
colnames(cens_ln_percentiles) <- quantiles_to_report
print(cens_ln_percentiles)
```

For each model, find these items for the estimated incubation period in the output above and write them below.

-   Mean and 95% credible interval

-   Standard deviation and 95% credible interval

-   Percentiles (e.g., 2.5, 5, 25, 50, 75, 95, 97.5, 99)

-   The parameters of the fitted distributions (e.g., shape and scale for gamma distribution)

#### **7.1.5. Plot the results**

```{r plot ip}
# Prepare results for plotting
df <- data.frame(
#Take mean values to draw empirical cumulative density function
  inc_day = ((input_data$tSymptomOnset-input_data$tEndExposure)+(input_data$tSymptomOnset-input_data$tStartExposure))/2
)

x_plot <- seq(0, 30, by=0.1) # This sets the range of the x axis (number of days)

Gam_plot <- as.data.frame(list(dose= x_plot, 
                               pred= sapply(x_plot, function(q) quantile(pgamma(q = q, shape = pos$gamma[,1], rate = pos$gamma[,2]), probs = c(0.5))),
                               low = sapply(x_plot, function(q) quantile(pgamma(q = q, shape = pos$gamma[,1], rate = pos$gamma[,2]), probs = c(0.025))),
                               upp = sapply(x_plot, function(q) quantile(pgamma(q = q, shape = pos$gamma[,1], rate = pos$gamma[,2]), probs = c(0.975)))
))

Wei_plot <- as.data.frame(list(dose= x_plot, 
                               pred= sapply(x_plot, function(q) quantile(pweibull(q = q, shape = pos$weibull[,1], scale = pos$weibull[,2]), probs = c(0.5))),
                               low = sapply(x_plot, function(q) quantile(pweibull(q = q, shape = pos$weibull[,1], scale = pos$weibull[,2]), probs = c(0.025))),
                               upp = sapply(x_plot, function(q) quantile(pweibull(q = q, shape = pos$weibull[,1], scale = pos$weibull[,2]), probs = c(0.975)))
))

ln_plot <- as.data.frame(list(dose= x_plot, 
                              pred= sapply(x_plot, function(q) quantile(plnorm(q = q, meanlog = pos$lognormal[,1], sdlog= pos$lognormal[,2]), probs = c(0.5))),
                              low = sapply(x_plot, function(q) quantile(plnorm(q = q, meanlog = pos$lognormal[,1], sdlog= pos$lognormal[,2]), probs = c(0.025))),
                              upp = sapply(x_plot, function(q) quantile(plnorm(q = q, meanlog = pos$lognormal[,1], sdlog= pos$lognormal[,2]), probs = c(0.975)))
))

# Plot cumulative distribution curves
gamma_ggplot <- ggplot(df, aes(x=inc_day)) +
  stat_ecdf(geom = "step")+ 
  xlim(c(0, 30))+
  geom_line(data=Gam_plot, aes(x=x_plot, y=pred), color=RColorBrewer::brewer.pal(11, "RdBu")[11], linewidth=1) +
  geom_ribbon(data=Gam_plot, aes(x=x_plot,ymin=low,ymax=upp), fill = RColorBrewer::brewer.pal(11, "RdBu")[11], alpha=0.1) +
  theme_bw(base_size = 11)+
  labs(x="Incubation period (days)", y = "Proportion")+
  ggtitle("Gamma")

weibul_ggplot <- ggplot(df, aes(x=inc_day)) +
  stat_ecdf(geom = "step")+ 
  xlim(c(0, 30))+
  geom_line(data=Wei_plot, aes(x=x_plot, y=pred), color=RColorBrewer::brewer.pal(11, "RdBu")[11], linewidth=1) +
  geom_ribbon(data=Wei_plot, aes(x=x_plot,ymin=low,ymax=upp), fill = RColorBrewer::brewer.pal(11, "RdBu")[11], alpha=0.1) +
  theme_bw(base_size = 11)+
  labs(x="Incubation period (days)", y = "Proportion")+
  ggtitle("Weibull")

lognorm_ggplot <- ggplot(df, aes(x=inc_day)) +
  stat_ecdf(geom = "step")+ 
  xlim(c(0, 30))+
  geom_line(data=ln_plot, aes(x=x_plot, y=pred), color=RColorBrewer::brewer.pal(11, "RdBu")[11], linewidth=1) +
  geom_ribbon(data=ln_plot, aes(x=x_plot,ymin=low,ymax=upp), fill = RColorBrewer::brewer.pal(11, "RdBu")[11], alpha=0.1) +
  theme_bw(base_size = 11)+
  labs(x="Incubation period (days)", y = "Proportion")+
  ggtitle("Log normal")

(lognorm_ggplot|gamma_ggplot|weibul_ggplot) + plot_annotation(tag_levels = 'A') 

```

In the plots above, the black line is the empirical cumulative distribution (the data), while the blue curve is the fitted probability distribution with the 95% credible intervals. Make sure that the blue curve lays on top of the black line.

::: {.alert .alert-secondary}
* **Questions (6)***

-   Are the fitting of the distributions what you'd expect?
:::

#### 

# *`_______Wrap-up 2 _________`*

## 8. Estimating the serial interval

Now we will estimate the serial interval. Again, we'll do a naive estimate first by calculating the difference between the onset times of primary and secondary case pairs.

1.  Are there any instances of negative serial intervals in the data (e.g., symptom onset in the secondary case came before symptom onset in primary case)?

2.  Report the median serial interval as well as the minimum and maximum.

3.  Plot the distribution of the serial interval.

### 8.1. Naive estimate

```{r si naive}
contacts$diff <- as.numeric(contacts$secondary_onset_date - contacts$primary_onset_date)
summary(contacts$diff)
hist(contacts$diff, xlab = "Serial interval (days)", breaks = 25, main = "", col = "pink")
```

### 8.2. Censoring adjusted estimate

Now we will estimate the serial interval using an implementation of the `courseDataTools` package within the `EpiEstim` R package. This method accounts for double censoring and allows different probability distributions to be compared, but it does not adjust for right truncation or dynamical bias.

We will consider three probability distributions and select the one that best fits the data using WAIC or LOOIC. Recall that the best-fitting distribution will have the lowest WAIC or LOOIC.

Note that in `coarseDataTools`, the parameters for the distributions are slightly different than in rstan. Here, the parameters for the gamma distribution are shape and scale (<https://cran.r-project.org/web/packages/coarseDataTools/coarseDataTools.pdf>).

We will only run one MCMC chain for each distribution in the interest of time, but you should run more than one chain in practice to make sure the MCMC converges on the target distribution. We will use the default prior distributions, which can be found in the package documentation (see 'details' for the dic.fit.mcmc function here: <https://cran.r-project.org/web/packages/coarseDataTools/coarseDataTools.pdf>).

#### 8.2.1. Preparing the data

```{r si epiestim}
# Format interval-censored serial interval data

# Each line represents a transmission event 
# EL/ER show the lower/upper bound of the symptoms onset date in the primary case (infector)
# SL/SR show the same for the secondary case (infectee)
# type has entries 0 corresponding to doubly interval-censored data
# (see Reich et al. Statist. Med. 2009)
si_data <- contacts |>
  select(-primary_case_id, -secondary_case_id, -primary_onset_date, -secondary_onset_date,) |>
  rename(SL = diff) |>
  mutate(type = 0, EL = 0, ER = 1, SR = SL + 1) |>
  select(EL, ER, SL, SR, type)

```

#### 8.2.2. Fitting a gamma distribution for SI

Let's fit the gamma distribution to the serial interval data first.

```{r gamma}
overall_seed <- 3 # seed for the random number generator for MCMC
MCMC_seed <- 007

# We will run the model for 4000 iterations with the first 1000 samples discarded as burnin
n_mcmc_samples <- 3000 # number of samples to draw from the posterior (after the burnin)

params = list(
dist = "G", # Fitting a Gamma distribution for the SI
method = "MCMC", # MCMC using coarsedatatools
burnin = 1000, # number of burnin samples (samples discarded at the beginning of MCMC) 
n1 = 50, # n1 is the number of pairs of mean and sd of the SI that are drawn
n2 = 50) # n2 is the size of the posterior sample drawn for each pair of mean, sd of SI

mcmc_control <- make_mcmc_control(
seed = MCMC_seed,
burnin = params$burnin)

dist <- params$dist

config <- make_config(
list(
si_parametric_distr = dist,
mcmc_control = mcmc_control,
seed = overall_seed,
n1 = params$n1,
n2 = params$n2))

# Fitting the SI
si_fit_gamma <- coarseDataTools::dic.fit.mcmc(
dat = si_data,
dist = dist,
init.pars = init_mcmc_params(si_data, dist),
burnin = mcmc_control$burnin,
n.samples = n_mcmc_samples,
seed = mcmc_control$seed)

```

Let's look at the results.

```{r gamma check res, results=FALSE}

# Check convergence of MCMC chains 
converg_diag_gamma <- check_cdt_samples_convergence(si_fit_gamma@samples)
converg_diag_gamma


# Save MCMC samples in dataframe
si_samples_gamma <- data.frame(
type = 'Symptom onset',
shape = si_fit_gamma@samples$var1,
scale = si_fit_gamma@samples$var2,
p50 = qgamma(
p = 0.5, 
shape = si_fit_gamma@samples$var1, 
scale = si_fit_gamma@samples$var2)) |>
mutate( # Equation for conversion is here https://en.wikipedia.org/wiki/Gamma_distribution
mean = shape*scale,
sd = sqrt(shape*scale^2)
) 

# Get the mean, SD, and 95% CrI


si_summary_gamma <- 
  si_samples_gamma %>%
summarise(
mean_mean = quantile(mean,probs=.5),
mean_l_ci = quantile(mean,probs=.025),
mean_u_ci = quantile(mean,probs=.975),
sd_mean = quantile(sd, probs=.5),
sd_l_ci = quantile(sd,probs=.025),
sd_u_ci = quantile(sd,probs=.975)
)
si_summary_gamma

# Get the same summary statistics for the parameters of the distribution
si_samples_gamma |>
summarise(
shape_mean = quantile(shape, probs=.5),
shape_l_ci = quantile(shape, probs=.025),
shape_u_ci = quantile(shape, probs=.975),
scale_mean = quantile(scale, probs=.5),
scale_l_ci = quantile(scale, probs=.025),
scale_u_ci = quantile(scale, probs=.975)
)

# We will need these for plotting later
gamma_shape <- si_fit_gamma@ests['shape',][1]
gamma_rate <- 1 / si_fit_gamma@ests['scale',][1]

```

#### 8.2.3. Fitting a log normal distribution for SI

Now let's fit a log normal distribution to the serial interval data.

```{r log normal}
# We will run the model for 4000 iterations with the first 1000 samples discarded as burnin
n_mcmc_samples <- 3000 # number of samples to draw from the posterior (after the burnin)

params = list(
dist = "L", # Fitting a log normal distribution for the SI
method = "MCMC", # MCMC using coarsedatatools
burnin = 1000, # number of burnin samples (samples discarded at the beginning of MCMC) 
n1 = 50, # n1 is the number of pairs of mean and sd of the SI that are drawn
n2 = 50) # n2 is the size of the posterior sample drawn for each pair of mean, sd of SI

mcmc_control <- make_mcmc_control(
seed = MCMC_seed,
burnin = params$burnin)

dist <- params$dist

config <- make_config(
list(
si_parametric_distr = dist,
mcmc_control = mcmc_control,
seed = overall_seed,
n1 = params$n1,
n2 = params$n2))

# Fitting the serial interval
si_fit_lnorm <- coarseDataTools::dic.fit.mcmc(
dat = si_data,
dist = dist,
init.pars = init_mcmc_params(si_data, dist),
burnin = mcmc_control$burnin,
n.samples = n_mcmc_samples,
seed = mcmc_control$seed)
```

Let's check the results.

```{r log normal res, results=FALSE}
# Check convergence of MCMC chains
converg_diag_lnorm <- check_cdt_samples_convergence(si_fit_lnorm@samples)
converg_diag_lnorm


# Save MCMC samples in a dataframe
si_samples_lnorm <- data.frame(
type = 'Symptom onset',
meanlog = si_fit_lnorm@samples$var1,
sdlog = si_fit_lnorm@samples$var2,
p50 = qlnorm(
p = 0.5, 
meanlog = si_fit_lnorm@samples$var1, 
sdlog = si_fit_lnorm@samples$var2)) |>
mutate( # Equation for conversion is here https://en.wikipedia.org/wiki/Log-normal_distribution
mean = exp(meanlog + (sdlog^2/2)), 
sd = sqrt((exp(sdlog^2)-1) * (exp(2*meanlog + sdlog^2)))
)

# Get the mean, SD, and 95% CrI
si_summary_lnorm <- 
  si_samples_lnorm %>%
summarise(
mean_mean = quantile(mean,probs=.5),
mean_l_ci = quantile(mean,probs=.025),
mean_u_ci = quantile(mean,probs=.975),
sd_mean = quantile(sd, probs=.5),
sd_l_ci = quantile(sd,probs=.025),
sd_u_ci = quantile(sd,probs=.975)
)
si_summary_lnorm

# Now get the summary statistics for the parameters of the distribution
si_samples_lnorm |>
summarise(
meanlog_mean = quantile(meanlog, probs=.5),
meanlog_l_ci = quantile(meanlog, probs=.025),
meanlog_u_ci = quantile(meanlog, probs=.975),
sdlog_mean = quantile(sdlog, probs=.5),
sdlog_l_ci = quantile(sdlog, probs=.025),
sdlog_u_ci = quantile(sdlog, probs=.975)
)

lognorm_meanlog <- si_fit_lnorm@ests['meanlog',][1]
lognorm_sdlog <- si_fit_lnorm@ests['sdlog',][1]



```

#### 8.2.4. Fitting a Weibull distribution for SI

Finally, let's fit a Weibull distribution to the serial interval data.

```{r weibull, results = FALSE}
# We will run the model for 4000 iterations with the first 1000 samples discarded as burnin
n_mcmc_samples <- 3000 # number of samples to draw from the posterior (after the burnin)

params = list(
dist = "W", # Fitting a weibull distribution for the SI
method = "MCMC", # MCMC using coarsedatatools
burnin = 1000, # number of burnin samples (samples discarded at the beginning of MCMC) 
n1 = 50, # n1 is the number of pairs of mean and sd of the SI that are drawn
n2 = 50) # n2 is the size of the posterior sample drawn for each pair of mean, sd of SI

mcmc_control <- make_mcmc_control(
seed = MCMC_seed,
burnin = params$burnin)

dist <- params$dist

config <- make_config(
list(
si_parametric_distr = dist,
mcmc_control = mcmc_control,
seed = overall_seed,
n1 = params$n1,
n2 = params$n2))

# Fitting the serial interval 
si_fit_weibull <- coarseDataTools::dic.fit.mcmc(
dat = si_data,
dist = dist,
init.pars = init_mcmc_params(si_data, dist),
burnin = mcmc_control$burnin,
n.samples = n_mcmc_samples,
seed = mcmc_control$seed)
```

Now we'll check the results.

```{r weibull check res}
# Check convergence
converg_diag_weibull <- check_cdt_samples_convergence(si_fit_weibull@samples)
converg_diag_weibull


# Save MCMC samples in dataframe
si_samples_weibull <- data.frame(
type = 'Symptom onset',
shape = si_fit_weibull@samples$var1,
scale = si_fit_weibull@samples$var2,
p50 = qweibull(
p = 0.5, 
shape = si_fit_weibull@samples$var1, 
scale = si_fit_weibull@samples$var2)) |>
mutate( # Equation for conversion is here https://en.wikipedia.org/wiki/Weibull_distribution
mean = scale*gamma(1+1/shape),
sd = sqrt(scale^2*(gamma(1+2/shape)-(gamma(1+1/shape))^2))
) 

# Get the summary statistics
si_summary_weibull <- 
  si_samples_weibull %>%
summarise(
mean_mean = quantile(mean,probs=.5),
mean_l_ci = quantile(mean,probs=.025),
mean_u_ci = quantile(mean,probs=.975),
sd_mean = quantile(sd, probs=.5),
sd_l_ci = quantile(sd,probs=.025),
sd_u_ci = quantile(sd,probs=.975)
)
si_summary_weibull

# Now get the summary statistics for the parameters of the distribution
si_samples_weibull |>
summarise(
shape_mean = quantile(shape, probs=.5),
shape_l_ci = quantile(shape, probs=.025),
shape_u_ci = quantile(shape, probs=.975),
scale_mean = quantile(scale, probs=.5),
scale_l_ci = quantile(scale, probs=.025),
scale_u_ci = quantile(scale, probs=.975)
)

weibull_shape <- si_fit_weibull@ests['shape',][1]
weibull_scale <- si_fit_weibull@ests['scale',][1]

```

#### 8.2.5. Plot the results for SI

Now we will plot the three fitted distributions. Make sure the distributions fit the serial interval data well.

```{r plot dist}
ggplot()+
	theme_classic()+
	geom_bar(data = contacts, aes(x=diff), fill = "#FFAD05") +
	scale_y_continuous(limits = c(0,14), breaks = c(0,2,4,6,8,10,12,14), expand = c(0,0)) +
	stat_function(
		linewidth=.8,
		fun = function(z, shape, rate)(dgamma(z, shape, rate) * length(contacts$diff)),
		args = list(shape = gamma_shape, rate = gamma_rate),
		aes(linetype  = 'Gamma')
	) +
	stat_function(
		linewidth=.8,
		fun = function(z, meanlog, sdlog)(dlnorm(z, meanlog, sdlog) * length(contacts$diff)),
		args = list(meanlog = lognorm_meanlog, sdlog = lognorm_sdlog),
		aes(linetype ='Log normal')
	) +
	stat_function(
		linewidth=.8,
		fun = function(z, shape, scale)(dweibull(z, shape, scale) * length(contacts$diff)),
		args = list(shape = weibull_shape, scale = weibull_scale),
		aes(linetype ='Weibull')
	) +
	scale_linetype_manual(values = c('solid','twodash','dotted')) +
	labs(x = "Days", y = "Number of case pairs") + 
	theme(
		legend.position = c(0.75, 0.75),
		plot.margin = margin(.2,5.2,.2,.2, "cm"),
		legend.title = element_blank(),
	) 

```

Let's calculate the WAIC and LOOIC. `coarseDataTools` does not have a built-in way to do this, so we need to calculate the likelihood from the MCMC chains and use the `loo` R package.

```{r model comparison}
# Load likelihood functions from coarseDataTools
source("Functions/likelihood_function.R")

compare_gamma <- calc_looic_waic(symp = si_data, symp_si = si_fit_gamma, dist = "G")
compare_lnorm <- calc_looic_waic(symp = si_data, symp_si = si_fit_lnorm, dist = "L")
compare_weibull <- calc_looic_waic(symp = si_data, symp_si = si_fit_weibull, dist = "W")

# Print results
compare_gamma[["waic"]]$estimates
compare_lnorm[["waic"]]$estimates
compare_weibull[["waic"]]$estimates

compare_gamma[["looic"]]$estimates
compare_lnorm[["looic"]]$estimates
compare_weibull[["looic"]]$estimates

```

Include the following when reporting the serial interval:

-   Mean and 95% credible interval

-   Standard deviation and 95% credible interval

-   The parameters of the fitted distribution (e.g., shape and scale for gamma distribution)

::: {.alert .alert-secondary}
* **Questions (7)***

-   Which distribution(s) have the lowest WAIC and LOOIC??
:::

```{r model print_final_results}
si_summary_gamma
si_summary_lnorm
si_summary_weibull

```

# *`_______Wrap-up 3 _________`*

## 9. Control measures

### 9.1 Analyze the results altogether

::: {.alert .alert-secondary}
You have now finalized the statistical analysis コ

-   Compare the incubation period and the serial interval.

-   Which one is longer?

-   Does pre-symptomatic transmission occur with Disease X?

<!-- -->

-   Will isolating symptomatic individuals and tracing and quarantining their contacts be effective measures?

-   If not, which other measures can be implemented to slow the outbreak?
:::

### 9.2 Design a contact tracing strategy

Based on the estimated delays as well as the demographics of cases, design a contact tracing strategy for the outbreak, including a communications plan (hint: think about logistics).

## 10. True values

The true values used to simulate the epidemics were:

+---------------+:---------------:+:-------------:+:-------------------------:+
|               | Distribution    | Mean (days)   | Standard deviation (days) |
+---------------+-----------------+---------------+---------------------------+
| Group 1       | Log normal      | 5.7           | 4.6                       |
+---------------+-----------------+---------------+---------------------------+
| Group 2       | Weibull         | 7.1           | 3.7                       |
+---------------+-----------------+---------------+---------------------------+

: Table 2. True values of the ***incubation period.***

+--------------+:---------------:+:------------:+:-------------------------:+
|              | Distribution    | Mean (days)  | Standard deviation (days) |
+--------------+-----------------+--------------+---------------------------+
| Group 1      | Gamma           | 8.4          | 4.9                       |
+--------------+-----------------+--------------+---------------------------+
| Group 2      | Gamma           | 4.8          | 3.3                       |
+--------------+-----------------+--------------+---------------------------+

: Table 3. True values of the ***serial interval***.

How do your estimates compare with the true values? Discuss possible reasons for any differences.

::::::::::::::::::::::::::::::::::::: keypoints 

Revise si al final de esta lecci贸n adquiri贸 estas competencias:


- Comprender los conceptos clave de las distribuciones de retrasos epidemiol贸gicos para la Enfermedad X.

- Entender las estructuras de datos y las herramientas para el an谩lisis de datos de rastreo de contactos.

- Aprender c贸mo ajustar las estimaciones del intervalo serial y del per铆odo de incubaci贸n de la Enfermedad X teniendo en cuenta la censura por intervalo usando un marco de trabajo Bayesiano.

- Aprender a utilizar estos par谩metros para informar estrategias de control en un brote de un pat贸geno desconocido.

::::::::::::::::::::::::::::::::::::::::::::::::

## 11. Further resources

In this practical, we largely ignored biases due to right truncation and dynamical bias, partly due to a lack of readily available tools that implement all best practices. To learn more about how these biases could affect the estimation of epidemiological delay distributions in real-time, we recommend a tutorial on the `dynamicaltruncation` R package by Sam Abbott and Sang Woo Park (<https://github.com/parksw3/epidist-paper>).

## 12. Contributors

Kelly Charniga, Zachary Madewell, Zulma M. Cucunub谩


## 13. References

1.  Reich NG et al. Estimating incubation period distributions with coarse data. Stat Med. 2009;28:2769--84. PubMed <https://doi.org/10.1002/sim.3659>
2.  Miura F et al. Estimated incubation period for monkeypox cases confirmed in the Netherlands, May 2022. Euro Surveill. 2022;27(24):pii=2200448. <https://doi.org/10.2807/1560-7917.ES.2022.27.24.2200448>
3.  Abbott S, Park Sang W. Adjusting for common biases in infectious disease data when estimating distributions. 2022 [cited 7 November 2023]. <https://github.com/parksw3/dynamicaltruncation>
4.  Lessler J et al. Incubation periods of acute respiratory viral infections: a systematic review, The Lancet Infectious Diseases. 2009;9(5):291-300. [https://doi.org/10.1016/S1473-3099(09)70069-6](https://doi.org/10.1016/S1473-3099(09)70069-6){.uri}.
5.  Cori A et al. Estimate Time Varying Reproduction Numbers from Epidemic Curves. 2022 [cited 7 November 2023]. <https://github.com/mrc-ide/EpiEstim>
6.  Lambert B. A Student's Guide to Bayesian Statistics. Los Angeles, London, New Delhi, Singapore, Washington DC, Melbourne: SAGE, 2018.
7.  Vehtari A et al. Rank-normalization, folding, and localization: An improved R-hat for assessing convergence of MCMC. Bayesian Analysis 2021: Advance publication 1-28. <https://doi.org/10.1214/20-BA1221>
8.  Nishiura H et al. Serial interval of novel coronavirus (COVID-19) infections. Int J Infect Dis. 2020;93:284-286. <https://doi.org/10.1016/j.ijid.2020.02.060>


